{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging and AdaBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Setting\n",
    "\n",
    "* $N \\in \\mathbb{N}$ : the number of observation data\n",
    "* $D \\in \\mathbb{N}$ : the dimension of observation data\n",
    "* $X = (x_0, x_1, \\dots, x_{N-1})$ : the set of observation data. $x_n \\in \\mathbb{R}^D$\n",
    "* $t = (t_0, t_1, \\dots, t_{N-1})$ : the target labels. $t_n \\in \\{ 1, -1 \\}$\n",
    "* $y : \\mathbb{R}^D \\times \\Theta \\rightarrow \\{1, -1\\}$ : a binary classifier parametrized by $\\theta \\in \\Theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Theory \n",
    "\n",
    "In this notebook, we construct strong classifier from a given simple classifier, which we call a base classifier. \n",
    "\n",
    "## 2.1 Base classifier : decision stump\n",
    "\n",
    "First, let us consider an extremely simple classifier called decision stump. \n",
    "\n",
    "\n",
    "### 2.1.1 Definition \n",
    "\n",
    "A decision stump is characterized by parameter $\\theta = (d, a, s) \\in \\{ 0,1, \\dots, D-1 \\} \\times \\mathbb{R} \\times \\{ 1, -1 \\} $, whose prediction is given by\n",
    "$$\n",
    "\\begin{align}\n",
    "    y(x, (d,a,s)) = \n",
    "    \\begin{cases}\n",
    "        s & (x^{(d)} \\geq a ) \\\\\n",
    "        -s & (x^{(d)} < a)\n",
    "    \\end{cases}\n",
    "\\end{align}\n",
    "$$\n",
    "where $x \\in \\mathbb{R}^D$ and $x^{(d)}$ stands for its $d$th component.\n",
    "In essence, the decision stump $y(\\cdot, (d,a,s))$ makes prediction according to whether the $d$ th coordinate of the input is smaller than $a$ or not. \n",
    "\n",
    "### 2.1.2 Training\n",
    "In training a decision stump, we choose a parameter $\\theta$ that minimizes\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\sum_{n=0}^{N-1} w_n I\\left[ y(x_n, \\theta) \\neq t_n \\right], \n",
    "\\end{align}\n",
    "$$\n",
    "where $w_n$ stands for sample weight, and will be specified later depending on the algorithm we consider.\n",
    "\n",
    "Given training data $x_0, \\dots, x_{N-1}$, we only consider $2D(N-1)$ possible decision stumps because\n",
    "* there are two ways of choosing the sign $s$, \n",
    "* there are $D$ possible ways of choosing the dimension $d$, and\n",
    "* although there are infinitely many ways of choosing $a$, here we limit the possible values of $a$ to be the average of two adjacent (in terms of $d$ the coordinate) training data points, which result in $N-1$ choices. \n",
    "\n",
    "As to the final point: The limitation does not affect the values of the error function, although it affects prediction error. Also, we assume that the training data is not single class (i.e., there are $n$ and $m$ such that $t_n \\neq t_m$ ).\n",
    "\n",
    "In the later implementation, we perform this exhaustive search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Bagging \n",
    "\n",
    "The idea of bagging, or bootstrap aggregation, is to train $M$ base classifiers using different \"training data\" for each classifier, where we obtain the \"training data\" by resampling from the original training data. \n",
    "\n",
    "### 2.2.1 Training \n",
    "\n",
    "For $m = 0,1, \\dots, M-1$, \n",
    "1. randomly sample $N$ data points from $(X,T)$ with replacement, and\n",
    "2. train the $m$ th classifier $y(\\cdot, \\theta_m)$ using the resampled data. \n",
    "\n",
    "### 2.2.2 Prediction \n",
    "\n",
    "Output the prediction for input $x$ by \n",
    "$$\n",
    "\\begin{align}\n",
    "    y_{bag}(x) = \\mathrm{sign} \\left[ \\sum_{m=0}^{M-1} y(x, \\theta_m) \\right]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "NOTE : Eq. (14.7) in the book is for regression, and for classification, we have to take sign to obtain meaningful result. We ommitted $1/M$ factor, because here we only care about sign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 AdaBoost\n",
    "\n",
    "NOTE : Formally, we can use other classifiers than decision stump for AdaBoost. However, in that case, the error function to be minimized by each base classifier is not necessarily $\\sum_{n=0}^{N-1} w^{(m)}_{n} I \\left[ y(x_n, \\theta_m) \\neq t_n \\right]$, and I am not sure whether it is theoretically sound or not.\n",
    "\n",
    "### 2.3.1 Training\n",
    "\n",
    "In AdaBoost, we train the classifier following the algorithm shown below: \n",
    "\n",
    "0. input : training data $(X, T)$, base classifier $y$, the number of boosting $M$. \n",
    "1. Initialize data weights $(w_0, w_1, \\dots, w_{N-1})$ as $w^{(0)}_{n} = 1/N$. \n",
    "2. For $m = 0, \\dots, M-1$: \n",
    "    1. Choose $\\theta_m \\in \\Theta$ such that\n",
    "    $$\n",
    "    \\begin{align}\n",
    "        \\sum_{n=0}^{N-1} w^{(m)}_{n} I \\left[ y(x_n, \\theta_m) \\neq t_n \\right]\n",
    "    \\end{align}\n",
    "    $$\n",
    "    is minimized.\n",
    "    2. Evalute \n",
    "    $$\n",
    "    \\begin{align}\n",
    "        \\varepsilon_m &:= \\sum_{n=0}^{N-1} w^{(m)}_{n}  I \\left[ y(x_n, \\theta_m) \\neq t_n \\right] \\\\     \n",
    "        \\alpha_m &:= \\log \\left(\\frac{1 - \\varepsilon_m}{\\varepsilon_m} \\right)\n",
    "    \\end{align}\n",
    "    $$\n",
    "    3. Update the data weight by \n",
    "    $$\n",
    "    \\begin{align}\n",
    "        \\tilde{w}^{(m+1)}_{n} &= w^{(m)}_{n} \\exp\\left\\{ \\alpha_m I \\left[ y(x_n, \\theta_m) \\neq t_n \\right]  \\right\\} \\\\\n",
    "        w^{(m+1)}_{n} &= \\frac{\\tilde{w}^{(m+1)}_{n}}{ \\sum_{n'=0}^{N-1} \\tilde{w}^{(m+1)}_{n'} }\n",
    "    \\end{align}\n",
    "    $$\n",
    "    \n",
    "NOTE :\n",
    "* We normalize the weight here, which results in apprently different (but intrinsically the same) definition of $\\varepsilon_m$ from (14.16) of the book.\n",
    "* It is implicitly assumed that the base classifier is better than random in the sense that $\\varepsilon_m < \\frac{1}{2}$ for all $m$. As far as I understand, the algorithm does not work when $\\varepsilon_m > \\frac{1}{2}$.\n",
    "\n",
    "### 2.3.2 Prediction \n",
    "\n",
    "Having obtained the classifier, the predicted label for input $x$ is given by \n",
    "$$\n",
    "\\begin{align}\n",
    "    \\textrm{sign} \\left[ \\sum_{m=0}^{M-1} \\alpha_m y(x, \\theta_m) \\right]\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 From math to code\n",
    "\n",
    "Here we define three classes, namely, `DecisionStump`, `Bagging`, and `AdaBoost`. \n",
    "\n",
    "We let `Bagging` and `AdaBoost` classes have `fit` and `predict` methods, and the following properties\n",
    "* `BaseClassifierClass` : the class from which base classifiers are generated (class, rather than instance should be given), which is assumed to implement `fit` and `predict` methods. For `AdaBoost` class, it is also assumed that the `fit` method of `BaseClassifierClass` can handle `sample_weight`.\n",
    "* `num_clfs` : $M$, i.e., the number of base classifiers used.\n",
    "* `clfs` :  list for storing base classifiers\n",
    "\n",
    "\n",
    "\n",
    "## 3.1  Decision stump\n",
    "\n",
    "We let our `DecisionStump` class to have the following properties\n",
    "* `axis` : $d$, i.e., the axis used for prediction\n",
    "* `sign` : $s$\n",
    "* `threshold` : $a$\n",
    "\n",
    "In fitting a decision stump, we \n",
    "* first perform the exhaustive search over $s$ and $a$ for each dimension using `fit_onedim` method (where the axis $d$ is given), and \n",
    "* then compare the result for each dimension $d$. \n",
    "\n",
    "In `fit_onedim`, we use the folowoing arrays, assuming that $X, T$ and $w$ are sorted according the value of the $d$th component of the input data $X$:  \n",
    "* `pred` : $(N-1, N)$ array, where `pred[m,n]` = $y\\left(x_n, \\left(d, \\frac{x_m + x_{m+1}}{2}, 1 \\right) \\right)$. Note that it can be generated easily by using np.tri (Although it is inefficient in terms of memory. ).\n",
    "* `mistakes` : $(N-1, N)$ array, where `mistakes[m,n]` = $I \\left[ y\\left(x_n, \\left(d, \\frac{x_m + x_{m+1}}{2}, 1 \\right) \\right) \\neq t_n\\right] $\n",
    "* `errs` : $(2, N-1)$ array, where \n",
    "    * `errs[0,m]` = $\\sum_{n=0}^{N-1} w_n I \\left[ y\\left(x_n, \\left(d, \\frac{x_m + x_{m+1}}{2}, 1 \\right) \\right) \\neq t_n\\right] $\n",
    "    * `errs[1,m]` = $\\sum_{n=0}^{N-1} w_n I \\left[ y\\left(x_n, \\left(d, \\frac{x_m + x_{m+1}}{2}, -1 \\right) \\right) \\neq t_n\\right] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionStump:\n",
    "    \n",
    "    def __init__(self, axis=None, sign=None, threshold=None):\n",
    "        self.axis = axis\n",
    "        self.sign = sign\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def fit_onedim(self, X, y, sample_weight, axis):\n",
    "        '''\n",
    "        Performing exhaustive search on threshold and sign, where the axis to consider is given.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2D numpy array\n",
    "            2D numpy array representing input data, where X[n, i] represents the i-th element of n-th point in X.\n",
    "        y : 1D numpy array\n",
    "            (len(X),) numpy array representing labels, where y[n] represents the label corresponding to n-th point in X.\n",
    "            Each element should be either 1 or -1\n",
    "        sample_weight : 1D numpy array\n",
    "            (len(X), ) numpy array representing the sample weights.\n",
    "            The elements should be non-negative.\n",
    "        axis : integer\n",
    "            A non-negative integer the axis to be considered.\n",
    "            Must be between 0 and X.shape(1)-1\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        sign : int, 1 or -1\n",
    "            Integer representing the sign s for the (candidate) decision stump\n",
    "        threshold : float\n",
    "            Threshold a for the (candidate) decision stump\n",
    "        err : float\n",
    "            Training error for the (candidate) decision stump\n",
    "        '''\n",
    "        N = len(X)\n",
    "        \n",
    "        # Here we sort everything according the axis-th coordinate of X\n",
    "        sort_ind = np.argsort(X[:, axis])\n",
    "        sorted_label = y[sort_ind]\n",
    "        sorted_input = X[sort_ind]\n",
    "        sorted_sample_weight = sample_weight[sort_ind]\n",
    "        \n",
    "        pred = -2*np.tri(N-1, N, k=0, dtype='int') + 1 \n",
    "        mistakes = (pred != sorted_label ).astype('int')\n",
    "        \n",
    "        # The (weighted) error is calculated for each classifier\n",
    "        errs = np.zeros((2, N-1))\n",
    "        errs[0] = mistakes @ sorted_sample_weight\n",
    "        errs[1] = (1 - mistakes) @ sorted_sample_weight\n",
    "    \n",
    "        # Here, we select the best threshold and sign\n",
    "        ind = np.unravel_index(np.argmin(errs, axis=None), errs.shape)\n",
    "        sign = -2*ind[0] + 1\n",
    "        threshold = ( sorted_input[ind[1], axis] + sorted_input[ind[1] + 1, axis] ) / 2\n",
    "        err = errs[ind]\n",
    "        return sign, threshold, err\n",
    "\n",
    "        \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        '''\n",
    "        Performing fitting by exhaustive search on threshold, sign, and axis.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2D numpy array\n",
    "            2D numpy array representing input data, where X[n, i] represents the i-th element of n-th point in X.\n",
    "        y : 1D numpy array\n",
    "            (len(X),) numpy array representing labels, where y[n] represents the label corresponding to n-th point in X.\n",
    "            Each element should be either 1 or -1\n",
    "        sample_weight : 1D numpy array\n",
    "            (len(X), ) numpy array representing the sample weights.\n",
    "            The elements should be non-negative.\n",
    "            If None, the sample_weight is assumed to be uniform.\n",
    "        '''\n",
    "        N, D = X.shape\n",
    "        \n",
    "        if sample_weight is None:\n",
    "            sample_weight = np.ones(N)/N\n",
    "        \n",
    "        signs = np.zeros(D)\n",
    "        threshs = np.zeros(D)\n",
    "        errs = np.zeros(D)\n",
    "        for axis in range(D):\n",
    "            signs[axis], threshs[axis], errs[axis] = self.fit_onedim(X, y, sample_weight, axis)\n",
    "        self.axis = np.argmin(errs)\n",
    "        self.sign = signs[self.axis]\n",
    "        self.threshold = threshs[self.axis]\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        The method predicts the labels for the given input data X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2D numpy array\n",
    "            2D numpy array representing input data, where X[n, i] represents the i-th element of n-th point in X.\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        y : 1D numpy array\n",
    "            (len(X),) numpy array representing the predicted labels, where y[n] represents the label corresponding to n-th point in X.\n",
    "        '''\n",
    "        return self.sign*( 2*(X[:, self.axis] >= self.threshold) - 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Bagging \n",
    "\n",
    "The implementation is rather straightforward. \n",
    "\n",
    "The code is written in a way that it can be used for other base classifiers, assuming that the base classifier class has `fit` and `predict` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bagging:\n",
    "    def __init__(self, BaseClassifierClass, num_clfs):\n",
    "        self.BaseClassifierClass = BaseClassifierClass # base classifier class\n",
    "        self.num_clfs = num_clfs\n",
    "        self.clfs = [self.BaseClassifierClass() for _ in range(self.num_clfs)]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        The method performs fitting by bagging using the given base classifier.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2D numpy array\n",
    "            2D numpy array representing input data, where X[n, i] represents the i-th element of n-th point in X.\n",
    "        y : 1D numpy array\n",
    "            (len(X),) numpy array representing labels, where y[n] represents the label corresponding to n-th point in X.\n",
    "            Each element should be either 1 or -1\n",
    "        '''\n",
    "        N = y.size\n",
    "        for clf in self.clfs:\n",
    "            bootstrap_idx = np.random.choice(np.arange(N), size=N, replace=True)\n",
    "            bootstrap_X, bootstrap_Y = X[bootstrap_idx, :], y[bootstrap_idx]\n",
    "            clf.fit(bootstrap_X, bootstrap_Y)\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        The method predicts the labels for the given input data X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2D numpy array\n",
    "            2D numpy array representing input data, where X[n, i] represents the i-th element of n-th point in X.\n",
    "        y : 1D numpy array\n",
    "            (len(X),) numpy array representing the predicted labels, where y[n] represents the label corresponding to n-th point in X.\n",
    "        '''\n",
    "        base_pred = np.zeros((self.num_clfs, len(X)))\n",
    "        for m in range(self.num_clfs):\n",
    "            base_pred[m] = self.clfs[m].predict(X)\n",
    "        return np.sign(  np.sum(base_pred, axis = 0 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 AdaBoost\n",
    "\n",
    "Just like the `Bagging` class, the code is written in a way that it can be used for other base classifiers, asuming that the base classifier class has \n",
    "* `fit` method which takes input data, label, and sample weight, and \n",
    "* `predict` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    def __init__(self, BaseClassifierClass, num_clfs):\n",
    "        self.BaseClassifierClass = BaseClassifierClass # base classifier class\n",
    "        self.num_clfs = num_clfs\n",
    "        self.alpha = np.zeros(self.num_clfs)\n",
    "        self.clfs = [self.BaseClassifierClass() for _ in range(self.num_clfs)]\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        The method performs fitting by AdaBoost using the given base classifier.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2D numpy array\n",
    "            2D numpy array representing input data, where X[n, i] represents the i-th element of n-th point in X.\n",
    "        y : 1D numpy array\n",
    "            (len(X),) numpy array representing labels, where y[n] represents the label corresponding to n-th point in X.\n",
    "            Each element should be either 1 or -1\n",
    "        '''\n",
    "        \n",
    "        # Initialize data weights $(w_0, w_1, \\dots, w_{N-1})$ as $w ^ {(0)}_{n} = 1/N$.\n",
    "        N = y.size\n",
    "        w = (1/N)*np.ones(N)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        The method predicts the labels for the given input data X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 2D numpy array\n",
    "            2D numpy array representing input data, where X[n, i] represents the i-th element of n-th point in X.\n",
    "        y : 1D numpy array\n",
    "            (len(X),) numpy array representing the predicted labels, where y[n] represents the label corresponding to n-th point in X.\n",
    "        '''\n",
    "        base_pred = np.zeros((self.num_clfs, len(X)))\n",
    "        for m in range(self.num_clfs):\n",
    "            base_pred[m] = self.clfs[m].predict(X)\n",
    "        return np.sign( base_pred.T @ self.alpha )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4 Experiment\n",
    "\n",
    "## 4.1 Data and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meshgrid(x, y, nx, ny, margin=0.1):\n",
    "    x_min, x_max = (1 + margin) * x.min() - margin * x.max(), (1 + margin) * x.max() - margin * x.min()\n",
    "    y_min, y_max = (1 + margin) * y.min() - margin * y.max(), (1 + margin) * y.max() - margin * y.min()\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, nx),\n",
    "                         np.linspace(y_min, y_max, ny))\n",
    "    return xx, yy\n",
    "\n",
    "\n",
    "def plot_result(ax, clf, xx, yy, X, y):\n",
    "    pred = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, pred, alpha=0.7)\n",
    "    ax.scatter(X[:,0], X[:,1], c=y, edgecolor='k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "X, y = datasets.make_moons(n_samples = 50, noise = 0.1, random_state=1)\n",
    "y = 2*y-1\n",
    "plt.scatter(X[:,0], X[:,1], c=y, edgecolor='k')\n",
    "\n",
    "xx, yy = get_meshgrid(X[:, 0], X[:, 1], nx=100, ny=100, margin=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "58988413135c144ab69024271f756817dc67fc434921cdaee00e451a2907f25b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('Projet-ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
